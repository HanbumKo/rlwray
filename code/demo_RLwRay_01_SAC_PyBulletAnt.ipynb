{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous SAC with PyBullet Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged loaded. TF version is [1.14.0].\n"
     ]
    }
   ],
   "source": [
    "import datetime,gym,os,pybullet_envs,time,os,psutil,ray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from util import gpu_sess,suppress_tf_warning\n",
    "from sac import ReplayBuffer,create_sac_model,create_sac_graph\n",
    "np.set_printoptions(precision=2)\n",
    "suppress_tf_warning() # suppress warning \n",
    "gym.logger.set_level(40) # gym logger \n",
    "print (\"Packaged loaded. TF version is [%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout worker classes (with and without RAY) ready.\n"
     ]
    }
   ],
   "source": [
    "class RolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Worker without RAY (for update purposes)\n",
    "    \"\"\"\n",
    "    def __init__(self,lr=1e-3,gamma=0.99,alpha=0.1,polyak=0.995,seed=1):\n",
    "        self.seed = seed\n",
    "        # Each worker should maintain its own environment\n",
    "        import pybullet_envs,gym\n",
    "        from util import suppress_tf_warning\n",
    "        suppress_tf_warning() # suppress TF warnings\n",
    "        gym.logger.set_level(40) # gym logger \n",
    "        \n",
    "        self.env = gym.make('AntBulletEnv-v0')\n",
    "        odim,adim = self.env.observation_space.shape[0],self.env.action_space.shape[0]\n",
    "        self.odim = odim\n",
    "        self.adim = adim\n",
    "        \n",
    "        # Create SAC model and computational graph \n",
    "        self.model,self.sess = create_sac_model(odim=self.odim,adim=self.adim)\n",
    "        self.step_ops,self.target_init = \\\n",
    "            create_sac_graph(self.model,lr=lr,gamma=gamma,alpha=alpha,polyak=polyak)\n",
    "        \n",
    "        # Initialize model \n",
    "        tf.set_random_seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(self.target_init)\n",
    "    \n",
    "    def get_action(self,o,deterministic=False):\n",
    "        act_op = self.model['mu'] if deterministic else self.model['pi']\n",
    "        return self.sess.run(act_op, feed_dict={self.model['o_ph']:o.reshape(1,-1)})[0]\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Get weights\n",
    "        \"\"\"\n",
    "        weight_vals = self.sess.run(self.model['main_vars'])\n",
    "        return weight_vals\n",
    "    \n",
    "@ray.remote\n",
    "class RayRolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Rollout Worker with RAY\n",
    "    \"\"\"\n",
    "    def __init__(self,worker_id=0,ep_len_rollout=1000):\n",
    "        # Parse\n",
    "        self.worker_id = worker_id\n",
    "        self.ep_len_rollout = ep_len_rollout\n",
    "        # Each worker should maintain its own environment\n",
    "        import pybullet_envs,gym\n",
    "        from util import suppress_tf_warning\n",
    "        suppress_tf_warning() # suppress TF warnings\n",
    "        gym.logger.set_level(40) # gym logger \n",
    "\n",
    "        self.env = gym.make('AntBulletEnv-v0')\n",
    "        odim,adim = self.env.observation_space.shape[0],self.env.action_space.shape[0]\n",
    "        self.odim = odim\n",
    "        self.adim = adim\n",
    "        # Replay buffers to pass\n",
    "        self.o_buffer = np.zeros((self.ep_len_rollout,self.odim))\n",
    "        self.a_buffer = np.zeros((self.ep_len_rollout,self.adim))\n",
    "        self.r_buffer = np.zeros((self.ep_len_rollout))\n",
    "        self.o2_buffer = np.zeros((self.ep_len_rollout,self.odim))\n",
    "        self.d_buffer = np.zeros((self.ep_len_rollout))\n",
    "        # Create SAC model\n",
    "        self.model,self.sess = create_sac_model(odim=self.odim,adim=self.adim)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        print (\"Ray Worker [%d] Ready.\"%(self.worker_id))\n",
    "        \n",
    "        # Flag to initialize assign operations for 'set_weights()'\n",
    "        self.FIRST_SET_FLAG = True\n",
    "        \n",
    "        # Flag to initialize rollout\n",
    "        self.FIRST_ROLLOUT_FLAG = True\n",
    "        \n",
    "    def get_action(self,o,deterministic=False):\n",
    "        act_op = self.model['mu'] if deterministic else self.model['pi']\n",
    "        return self.sess.run(act_op, feed_dict={self.model['o_ph']:o.reshape(1,-1)})[0]\n",
    "    \n",
    "    def set_weights(self,weight_vals):\n",
    "        \"\"\"\n",
    "        Set weights without memory leakage\n",
    "        \"\"\"\n",
    "        if self.FIRST_SET_FLAG:\n",
    "            self.FIRST_SET_FLAG = False\n",
    "            self.assign_placeholders = []\n",
    "            self.assign_ops = []\n",
    "            for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "                a = weight_tf_var\n",
    "                assign_placeholder = tf.placeholder(a.dtype, shape=a.get_shape())\n",
    "                assign_op = a.assign(assign_placeholder)\n",
    "                self.assign_placeholders.append(assign_placeholder)\n",
    "                self.assign_ops.append(assign_op)\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "            # Memory-leakage-free assign (hopefully)\n",
    "            self.sess.run(self.assign_ops[w_idx],\n",
    "                          {self.assign_placeholders[w_idx]:weight_vals[w_idx]})\n",
    "            \n",
    "    def rollout(self):\n",
    "        \"\"\"\n",
    "        Rollout\n",
    "        \"\"\"\n",
    "        if self.FIRST_ROLLOUT_FLAG:\n",
    "            self.FIRST_ROLLOUT_FLAG = False\n",
    "            self.o = self.env.reset() # reset environment\n",
    "        # Loop\n",
    "        for t in range(ep_len_rollout):\n",
    "            self.a = self.get_action(self.o,deterministic=False) \n",
    "            self.o2,self.r,self.d,_ = self.env.step(self.a)\n",
    "            # Append\n",
    "            self.o_buffer[t,:] = self.o\n",
    "            self.a_buffer[t,:] = self.a\n",
    "            self.r_buffer[t] = self.r\n",
    "            self.o2_buffer[t,:] = self.o2\n",
    "            self.d_buffer[t] = self.d\n",
    "            # Save next state \n",
    "            self.o = self.o2\n",
    "            if self.d: self.o = self.env.reset() # reset when done \n",
    "        return self.o_buffer,self.a_buffer,self.r_buffer,self.o2_buffer,self.d_buffer\n",
    "    \n",
    "print (\"Rollout worker classes (with and without RAY) ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize PyBullet Ant Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AntBulletEnv-v0] ready.\n"
     ]
    }
   ],
   "source": [
    "env_name = 'AntBulletEnv-v0'\n",
    "test_env = gym.make(env_name)\n",
    "_ = test_env.render(mode='human') # enable rendering on test_env\n",
    "_ = test_env.reset()\n",
    "for _ in range(3): # dummy run for proper rendering \n",
    "    a = test_env.action_space.sample()\n",
    "    o,r,d,_ = test_env.step(a)\n",
    "    time.sleep(0.01)\n",
    "print (\"[%s] ready.\"%(env_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "odim,adim = o.shape[0],a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpu = n_workers = 15\n",
    "total_steps,evaluate_every = 5000,200\n",
    "ep_len_rollout = 100\n",
    "batch_size,update_count = 128,ep_len_rollout\n",
    "num_eval,max_ep_len_eval = 3,1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-22 01:30:12,922\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-06-22 01:30:12,926\tINFO resource_spec.py:212 -- Starting Ray with 4.98 GiB memory available for workers and up to 10.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-22 01:30:13,317\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAY initialized with [15] cpus and [15] workers.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=n_cpu,\n",
    "         memory = 5*1024*1024*1024,\n",
    "         object_store_memory = 10*1024*1024*1024,\n",
    "         driver_object_store_memory = 1*1024*1024*1024)\n",
    "tf.reset_default_graph()\n",
    "R = RolloutWorkerClass(lr=1e-3,gamma=0.99,alpha=0.1,polyak=0.995,seed=0)\n",
    "workers = [RayRolloutWorkerClass.remote(worker_id=i,ep_len_rollout=ep_len_rollout) \n",
    "           for i in range(n_workers)]\n",
    "print (\"RAY initialized with [%d] cpus and [%d] workers.\"%\n",
    "       (n_cpu,n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(odim=odim,adim=adim,size=int(1e6))\n",
    "replay_buffer_short = ReplayBuffer(odim=odim,adim=adim,size=int(1e5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=23270)\u001b[0m Ray Worker [14] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23267)\u001b[0m Ray Worker [13] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23274)\u001b[0m Ray Worker [4] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23272)\u001b[0m Ray Worker [2] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23277)\u001b[0m Ray Worker [0] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23276)\u001b[0m Ray Worker [12] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23279)\u001b[0m Ray Worker [8] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23269)\u001b[0m Ray Worker [7] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23280)\u001b[0m Ray Worker [3] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23278)\u001b[0m Ray Worker [5] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23271)\u001b[0m Ray Worker [10] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23268)\u001b[0m Ray Worker [1] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23273)\u001b[0m Ray Worker [9] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23275)\u001b[0m Ray Worker [11] Ready.\n",
      "\u001b[2m\u001b[36m(pid=23266)\u001b[0m Ray Worker [6] Ready.\n",
      "[Evaluate] step:[1/5000][0.0%] #step:[1.5e+03] time:[00:00:03] ram:[31.3%].\n",
      "[Evaluate] [0/3] ep_ret:[8.8756] ep_len:[20]\n",
      "[Evaluate] [1/3] ep_ret:[8.5296] ep_len:[20]\n",
      "[Evaluate] [2/3] ep_ret:[8.7337] ep_len:[20]\n",
      "[Evaluate] step:[200/5000][4.0%] #step:[3.0e+05] time:[00:03:21] ram:[35.0%].\n",
      "[Evaluate] [0/3] ep_ret:[742.9349] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[742.3742] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[695.7447] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:35:07.325994 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080b2100000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[400/5000][8.0%] #step:[6.0e+05] time:[00:06:44] ram:[35.3%].\n",
      "[Evaluate] [0/3] ep_ret:[806.5184] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[681.2826] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[853.0021] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:37:48.804764 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080e6190000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[600/5000][12.0%] #step:[9.0e+05] time:[00:10:08] ram:[35.6%].\n",
      "[Evaluate] [0/3] ep_ret:[798.2169] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[723.3907] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[743.8601] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:43:32.278857 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080fc2d0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[800/5000][16.0%] #step:[1.2e+06] time:[00:13:31] ram:[35.9%].\n",
      "[Evaluate] [0/3] ep_ret:[941.8172] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1070.4321] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[728.6688] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:46:13.632071 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008041370000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[1000/5000][20.0%] #step:[1.5e+06] time:[00:16:53] ram:[35.9%].\n",
      "[Evaluate] [0/3] ep_ret:[1385.3084] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1347.9613] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1312.8330] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:47:17.079569 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080a53a0000 was evicted before the raylet could pin it.\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:49:28.904525 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008081420000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[1200/5000][24.0%] #step:[1.8e+06] time:[00:20:16] ram:[35.9%].\n",
      "[Evaluate] [0/3] ep_ret:[1557.7501] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1640.1856] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1660.3170] ep_len:[1000]\n",
      "[Evaluate] step:[1400/5000][28.0%] #step:[2.1e+06] time:[00:23:40] ram:[36.0%].\n",
      "[Evaluate] [0/3] ep_ret:[1668.4704] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1618.5026] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1724.1041] ep_len:[1000]\n",
      "[Evaluate] step:[1600/5000][32.0%] #step:[2.4e+06] time:[00:27:03] ram:[36.0%].\n",
      "[Evaluate] [0/3] ep_ret:[1511.0551] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1560.2660] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1534.2896] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 01:59:25.954141 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080f3640000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[1800/5000][36.0%] #step:[2.7e+06] time:[00:30:25] ram:[36.1%].\n",
      "[Evaluate] [0/3] ep_ret:[1867.5620] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1637.9038] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1792.2622] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:00:49.695693 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008093690000 was evicted before the raylet could pin it.\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:02:18.713268 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080e86e0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[2000/5000][40.0%] #step:[3.0e+06] time:[00:33:47] ram:[36.3%].\n",
      "[Evaluate] [0/3] ep_ret:[1652.6858] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1790.2419] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1819.3856] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:04:43.082126 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008028770000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[2200/5000][44.0%] #step:[3.3e+06] time:[00:37:09] ram:[36.2%].\n",
      "[Evaluate] [0/3] ep_ret:[1675.8056] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1738.5709] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1814.7103] ep_len:[1000]\n",
      "[Evaluate] step:[2400/5000][48.0%] #step:[3.6e+06] time:[00:40:31] ram:[36.5%].\n",
      "[Evaluate] [0/3] ep_ret:[2050.8959] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2041.1751] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2022.6821] ep_len:[1000]\n",
      "[Evaluate] step:[2600/5000][52.0%] #step:[3.9e+06] time:[00:43:53] ram:[36.6%].\n",
      "[Evaluate] [0/3] ep_ret:[1735.3967] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1729.5460] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1720.5156] ep_len:[1000]\n",
      "[Evaluate] step:[2800/5000][56.0%] #step:[4.2e+06] time:[00:47:15] ram:[36.7%].\n",
      "[Evaluate] [0/3] ep_ret:[1608.6556] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1435.9285] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1541.3681] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:20:20.913391 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080bbad0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[3000/5000][60.0%] #step:[4.5e+06] time:[00:50:39] ram:[36.7%].\n",
      "[Evaluate] [0/3] ep_ret:[1659.4194] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1696.4800] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1554.3858] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:21:32.287447 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008098b10000 was evicted before the raylet could pin it.\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:24:02.849247 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff010000809fba0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[3200/5000][64.0%] #step:[4.8e+06] time:[00:54:01] ram:[36.8%].\n",
      "[Evaluate] [0/3] ep_ret:[2080.5376] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2035.3921] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2013.8568] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:25:34.238199 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080b6bf0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[3400/5000][68.0%] #step:[5.1e+06] time:[00:57:23] ram:[36.8%].\n",
      "[Evaluate] [0/3] ep_ret:[1838.0342] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1905.9777] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1901.6762] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:29:18.641703 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080c5cc0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[3600/5000][72.0%] #step:[5.4e+06] time:[01:00:45] ram:[36.9%].\n",
      "[Evaluate] [0/3] ep_ret:[2084.0836] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1924.9676] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2083.0165] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:31:58.733402 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080fbd50000 was evicted before the raylet could pin it.\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:33:13.877645 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff010000807fda0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[3800/5000][76.0%] #step:[5.7e+06] time:[01:04:07] ram:[37.0%].\n",
      "[Evaluate] [0/3] ep_ret:[1954.0232] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1937.0208] ep_len:[1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluate] [2/3] ep_ret:[1924.9499] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:34:52.481386 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080fedf0000 was evicted before the raylet could pin it.\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:37:03.308148 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff01000080d6e70000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[4000/5000][80.0%] #step:[6.0e+06] time:[01:07:29] ram:[37.0%].\n",
      "[Evaluate] [0/3] ep_ret:[2163.5112] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1926.7001] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2056.0654] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:38:07.672744 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff010000804deb0000 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[4200/5000][84.0%] #step:[6.3e+06] time:[01:10:51] ram:[37.1%].\n",
      "[Evaluate] [0/3] ep_ret:[1722.7748] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2016.1374] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1157.9974] ep_len:[1000]\n",
      "[Evaluate] step:[4400/5000][88.0%] #step:[6.6e+06] time:[01:14:12] ram:[37.1%].\n",
      "[Evaluate] [0/3] ep_ret:[2056.7950] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2081.7808] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1906.8091] ep_len:[1000]\n",
      "[Evaluate] step:[4600/5000][92.0%] #step:[6.9e+06] time:[01:17:34] ram:[37.1%].\n",
      "[Evaluate] [0/3] ep_ret:[2137.4513] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2152.3553] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2148.0842] ep_len:[1000]\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:49:18.996202 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008072120100 was evicted before the raylet could pin it.\n",
      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0622 02:50:20.461014 23251 node_manager.cc:3118] Plasma object ffffffffffffffffffffffff0100008023160100 was evicted before the raylet could pin it.\n",
      "[Evaluate] step:[4800/5000][96.0%] #step:[7.2e+06] time:[01:20:56] ram:[37.2%].\n",
      "[Evaluate] [0/3] ep_ret:[2217.8008] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2173.4326] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2217.4432] ep_len:[1000]\n",
      "[Evaluate] step:[5000/5000][100.0%] #step:[7.5e+06] time:[01:24:17] ram:[37.3%].\n",
      "[Evaluate] [0/3] ep_ret:[2076.0343] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1841.2884] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2142.6984] ep_len:[1000]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "n_env_step = 0 # number of environment steps\n",
    "for t in range(int(total_steps)):\n",
    "    esec = time.time()-start_time\n",
    "    \n",
    "    # Synchronize worker weights\n",
    "    weights = R.get_weights()\n",
    "    set_weights_list = [worker.set_weights.remote(weights) for worker in workers] \n",
    "    \n",
    "    # Make rollout and accumulate to Buffers\n",
    "    ops = [worker.rollout.remote() for worker in workers]\n",
    "    rollout_vals = ray.get(ops)\n",
    "    for rollout_val in rollout_vals:\n",
    "        o_buffer,a_buffer,r_buffer,o2_buffer,d_buffer = rollout_val\n",
    "        for i in range(ep_len_rollout):\n",
    "            o,a,r,o2,d = o_buffer[i,:],a_buffer[i,:],r_buffer[i],o2_buffer[i,:],d_buffer[i]\n",
    "            replay_buffer.store(o, a, r, o2, d) \n",
    "            replay_buffer_short.store(o, a, r, o2, d) \n",
    "            n_env_step += 1\n",
    "    \n",
    "    # Update\n",
    "    for _ in range(int(update_count)):\n",
    "        batch = replay_buffer.sample_batch(batch_size//2) \n",
    "        batch_short = replay_buffer_short.sample_batch(batch_size//2) \n",
    "        feed_dict = {R.model['o_ph']: np.concatenate((batch['obs1'],batch_short['obs1'])),\n",
    "                     R.model['o2_ph']: np.concatenate((batch['obs2'],batch_short['obs2'])),\n",
    "                     R.model['a_ph']: np.concatenate((batch['acts'],batch_short['acts'])),\n",
    "                     R.model['r_ph']: np.concatenate((batch['rews'],batch_short['rews'])),\n",
    "                     R.model['d_ph']: np.concatenate((batch['done'],batch_short['done']))\n",
    "                    }\n",
    "        outs = R.sess.run(R.step_ops, feed_dict)\n",
    "    \n",
    "    # Evaluate\n",
    "    if (t == 0) or (((t+1)%evaluate_every) == 0): \n",
    "        ram_percent = psutil.virtual_memory().percent # memory usage\n",
    "        print (\"[Evaluate] step:[%d/%d][%.1f%%] #step:[%.1e] time:[%s] ram:[%.1f%%].\"%\n",
    "               (t+1,total_steps,t/total_steps*100,\n",
    "                n_env_step,\n",
    "                time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                ram_percent)\n",
    "              )\n",
    "        for eval_idx in range(num_eval): \n",
    "            o,d,ep_ret,ep_len = test_env.reset(),False,0,0\n",
    "            _ = test_env.render(mode='human') \n",
    "            while not(d or (ep_len == max_ep_len_eval)):\n",
    "                a = R.get_action(o,deterministic=True)\n",
    "                o,r,d,_ = test_env.step(a)\n",
    "                _ = test_env.render(mode='human') \n",
    "                ep_ret += r # compute return \n",
    "                ep_len += 1\n",
    "            print (\"[Evaluate] [%d/%d] ep_ret:[%.4f] ep_len:[%d]\"\n",
    "                %(eval_idx,num_eval,ep_ret,ep_len))\n",
    "    \n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AntBulletEnv-v0] ready.\n",
      "[Evaluate] ep_ret:[2.0000] ep_len:[1000]\n"
     ]
    }
   ],
   "source": [
    "gym.logger.set_level(40)\n",
    "env_name = 'AntBulletEnv-v0'\n",
    "test_env = gym.make(env_name)\n",
    "_ = test_env.render(mode='human') # enable rendering on test_env\n",
    "_ = test_env.reset()\n",
    "for _ in range(3): # dummy run for proper rendering \n",
    "    a = test_env.action_space.sample()\n",
    "    o,r,d,_ = test_env.step(a)\n",
    "    time.sleep(0.01)\n",
    "print (\"[%s] ready.\"%(env_name))\n",
    "o,d,ep_ret,ep_len = test_env.reset(),False,0,0\n",
    "_ = test_env.render(mode='human') \n",
    "while not(d or (ep_len == max_ep_len_eval)):\n",
    "    a = R.get_action(o,deterministic=True)\n",
    "    o,r,d,_ = test_env.step(a)\n",
    "    _ = test_env.render(mode='human') \n",
    "    ep_ret += r # compute return \n",
    "    ep_len += 1\n",
    "print (\"[Evaluate] ep_ret:[%.4f] ep_len:[%d]\"\n",
    "    %(eval_idx,ep_len))\n",
    "test_env.close() # close env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

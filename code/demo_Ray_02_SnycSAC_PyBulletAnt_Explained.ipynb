{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snychronous SAC with PyBullet Ant Env  <font color='grey'> (*Self-Contained*) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged loaded. TF version is [1.14.0].\n"
     ]
    }
   ],
   "source": [
    "import os,ray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from util import gpu_sess,suppress_tf_warning\n",
    "np.set_printoptions(precision=2)\n",
    "print (\"Packaged loaded. TF version is [%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppress_tf_warning() # suppress warning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 21:15:01,616\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-06-18 21:15:01,619\tINFO resource_spec.py:212 -- Starting Ray with 16.16 GiB memory available for workers and up to 8.1 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-18 21:15:01,976\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAY initialized with [5] cpus.\n"
     ]
    }
   ],
   "source": [
    "n_cpus = 5\n",
    "ray.init(num_cpus=n_cpus)\n",
    "print (\"RAY initialized with [%d] cpus.\"%(n_cpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAC model ready.\n"
     ]
    }
   ],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A simple FIFO experience replay buffer for SAC agents.\n",
    "    \"\"\"\n",
    "    def __init__(self, odim, adim, size):\n",
    "        self.obs1_buf = np.zeros([size, odim], dtype=np.float32)\n",
    "        self.obs2_buf = np.zeros([size, odim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size, adim], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs1_buf[self.ptr] = obs\n",
    "        self.obs2_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr+1) % self.max_size\n",
    "        self.size = min(self.size+1, self.max_size)\n",
    "    def sample_batch(self, batch_size=32):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        return dict(obs1=self.obs1_buf[idxs],\n",
    "                    obs2=self.obs2_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "    \n",
    "def create_sac_model(odim=10,adim=2,hdims=[256,256]):\n",
    "    \"\"\"\n",
    "    Soft Actor Critic Model (compatible with Ray)\n",
    "    \"\"\"\n",
    "    import tensorflow as tf # make it compatible with Ray actors\n",
    "    \n",
    "    def mlp(x,hdims=[256,256],actv=tf.nn.relu,out_actv=tf.nn.relu):\n",
    "        ki = tf.truncated_normal_initializer(stddev=0.1)\n",
    "        for hdim in hdims[:-1]:\n",
    "            x = tf.layers.dense(x,units=hdim,activation=actv,kernel_initializer=ki)\n",
    "        return tf.layers.dense(x,units=hdims[-1],activation=out_actv,kernel_initializer=ki)\n",
    "    def gaussian_loglik(x,mu,log_std):\n",
    "        EPS = 1e-8\n",
    "        pre_sum = -0.5*(\n",
    "            ( (x-mu)/(tf.exp(log_std)+EPS) )**2 +\n",
    "            2*log_std + np.log(2*np.pi)\n",
    "        )\n",
    "        return tf.reduce_sum(pre_sum, axis=1)\n",
    "    def mlp_gaussian_policy(o,adim=2,hdims=[256,256],actv=tf.nn.relu):\n",
    "        net = mlp(x=o,hdims=hdims,actv=actv,out_actv=actv) # feature \n",
    "        mu = tf.layers.dense(net,adim,activation=None) # mu\n",
    "        log_std = tf.layers.dense(net,adim,activation=None) # log_std\n",
    "        LOG_STD_MIN,LOG_STD_MAX = -10.0,+2.0\n",
    "        log_std = tf.clip_by_value(log_std, LOG_STD_MIN, LOG_STD_MAX) \n",
    "        std = tf.exp(log_std) # std \n",
    "        pi = mu + tf.random_normal(tf.shape(mu)) * std  # sampled\n",
    "        logp_pi = gaussian_loglik(x=pi,mu=mu,log_std=log_std) # log lik\n",
    "        return mu,pi,logp_pi\n",
    "    def squash_action(mu,pi,logp_pi):\n",
    "        # Squash those unbounded actions\n",
    "        logp_pi -= tf.reduce_sum(2*(np.log(2) - pi -\n",
    "                                    tf.nn.softplus(-2*pi)), axis=1)\n",
    "        mu,pi = tf.tanh(mu),tf.tanh(pi)\n",
    "        return mu, pi, logp_pi\n",
    "    def mlp_actor_critic(o,a,hdims=[256,256],actv=tf.nn.relu,out_actv=None,\n",
    "                         policy=mlp_gaussian_policy):\n",
    "        adim = a.shape.as_list()[-1]\n",
    "        with tf.variable_scope('pi'): # policy\n",
    "            mu,pi,logp_pi = policy(o=o,adim=adim,hdims=hdims,actv=actv)\n",
    "            mu,pi,logp_pi = squash_action(mu=mu,pi=pi,logp_pi=logp_pi)\n",
    "        def vf_mlp(x): return tf.squeeze(\n",
    "            mlp(x=x,hdims=hdims+[1],actv=actv,out_actv=None),axis=1)\n",
    "        with tf.variable_scope('q1'): q1 = vf_mlp( tf.concat([o,a],axis=-1))\n",
    "        with tf.variable_scope('q2'): q2 = vf_mlp( tf.concat([o,a],axis=-1))\n",
    "        return mu,pi,logp_pi,q1,q2\n",
    "    \n",
    "    def placeholder(dim=None):\n",
    "        return tf.placeholder(dtype=tf.float32,shape=(None,dim) if dim else (None,))\n",
    "    def placeholders(*args):\n",
    "        \"\"\"\n",
    "        Usage: a_ph,b_ph,c_ph = placeholders(adim,bdim,None)\n",
    "        \"\"\"\n",
    "        return [placeholder(dim) for dim in args]\n",
    "    def get_vars(scope):\n",
    "        return [x for x in tf.compat.v1.global_variables() if scope in x.name]\n",
    "    \n",
    "    # Have own session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    # Placeholders\n",
    "    o_ph,a_ph,o2_ph,r_ph,d_ph = placeholders(odim,adim,odim,None,None)\n",
    "    # Actor critic \n",
    "    ac_kwargs = {'hdims':hdims,'actv':tf.nn.relu,'out_actv':None,'policy':mlp_gaussian_policy}\n",
    "    with tf.variable_scope('main'):\n",
    "        mu,pi,logp_pi,q1,q2 = mlp_actor_critic(o=o_ph,a=a_ph,**ac_kwargs)\n",
    "    with tf.variable_scope('main',reuse=True):\n",
    "        _,_,_,q1_pi,q2_pi = mlp_actor_critic(o=o_ph,a=pi,**ac_kwargs)\n",
    "        _,pi_next,logp_pi_next,_,_ = mlp_actor_critic(o=o2_ph,a=a_ph,**ac_kwargs)\n",
    "    # Target value\n",
    "    with tf.variable_scope('target'):\n",
    "        _,_,_,q1_targ,q2_targ = mlp_actor_critic(o=o2_ph,a=pi_next,**ac_kwargs)\n",
    "        \n",
    "    # Get variables\n",
    "    main_vars,q_vars,pi_vars,target_vars = \\\n",
    "        get_vars('main'),get_vars('main/q'),get_vars('main/pi'),get_vars('target')\n",
    "    \n",
    "    model = {'o_ph':o_ph,'a_ph':a_ph,'o2_ph':o2_ph,'r_ph':r_ph,'d_ph':d_ph,\n",
    "             'mu':mu,'pi':pi,'logp_pi':logp_pi,'q1':q1,'q2':q2,\n",
    "             'q1_pi':q1_pi,'q2_pi':q2_pi,\n",
    "             'pi_next':pi_next,'logp_pi_next':logp_pi_next,\n",
    "             'q1_targ':q1_targ,'q2_targ':q2_targ,\n",
    "             'main_vars':main_vars,'q_vars':q_vars,'pi_vars':pi_vars,'target_vars':target_vars}\n",
    "        \n",
    "    return model,sess\n",
    "\n",
    "def create_sac_graph(model,lr=1e-3,gamma=0.98,alpha=0.1,polyak=0.995):\n",
    "    \"\"\"\n",
    "    SAC Computational Graph\n",
    "    \"\"\"\n",
    "    # Double Q-learning\n",
    "    min_q_pi = tf.minimum(model['q1_pi'],model['q2_pi'])\n",
    "    min_q_targ = tf.minimum(model['q1_targ'],model['q2_targ'])\n",
    "    \n",
    "    # Entropy-regularized Bellman backup\n",
    "    q_backup = tf.stop_gradient(\n",
    "        model['r_ph'] + \n",
    "        gamma*(1-model['d_ph'])*(min_q_targ - alpha*model['logp_pi_next'])\n",
    "    )\n",
    "    \n",
    "    # Soft actor-critic losses\n",
    "    pi_loss = tf.reduce_mean(alpha*model['logp_pi'] - min_q_pi)\n",
    "    q1_loss = 0.5 * tf.reduce_mean((q_backup - model['q1'])**2)\n",
    "    q2_loss = 0.5 * tf.reduce_mean((q_backup - model['q2'])**2)\n",
    "    value_loss = q1_loss + q2_loss\n",
    "    \n",
    "    # Policy train op\n",
    "    pi_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_pi_op = pi_optimizer.minimize(pi_loss,var_list=model['pi_vars'])\n",
    "    \n",
    "    # Value train op \n",
    "    value_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    with tf.control_dependencies([train_pi_op]):\n",
    "        train_value_op = value_optimizer.minimize(value_loss,var_list=model['q_vars'])\n",
    "        \n",
    "    # Polyak averaging for target variables\n",
    "    with tf.control_dependencies([train_value_op]):\n",
    "        target_update = tf.group([tf.assign(v_targ, polyak*v_targ + (1-polyak)*v_main)\n",
    "                                  for v_main, v_targ in \n",
    "                                      zip(model['main_vars'], model['target_vars'])]\n",
    "                                )\n",
    "    \n",
    "    # All ops to call during one training step\n",
    "    step_ops = [pi_loss, q1_loss, q2_loss, model['q1'], model['q2'], model['logp_pi'],\n",
    "                train_pi_op, train_value_op, target_update]\n",
    "    \n",
    "    # Initializing targets to match main variables\n",
    "    target_init = tf.group([tf.assign(v_targ, v_main)\n",
    "                            for v_main, v_targ in \n",
    "                                zip(model['main_vars'], model['target_vars'])]\n",
    "                          )\n",
    "\n",
    "    return step_ops,target_init\n",
    "    \n",
    "def get_action(model,sess,o,deterministic=False):\n",
    "    act_op = model['mu'] if deterministic else model['pi']\n",
    "    return sess.run(act_op, feed_dict={model['o_ph']:o.reshape(1,-1)})[0]\n",
    "\n",
    "print (\"SAC model ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout Worker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout worker classes (with and without RAY) ready.\n"
     ]
    }
   ],
   "source": [
    "class RolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Worker without RAY (for update purposes)\n",
    "    \"\"\"\n",
    "    def __init__(self,odim=10,adim=2):\n",
    "        self.odim = odim\n",
    "        self.adim = adim\n",
    "        self.model,self.sess = create_sac_model(odim=self.odim,adim=self.adim)\n",
    "        self.step_ops,self.target_init = \\\n",
    "            create_sac_graph(self.model,lr=1e-3,gamma=0.98,alpha=0.1,polyak=0.995)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(self.target_init)\n",
    "    def get_weights(self):\n",
    "        weight_vals = self.sess.run(self.model['main_vars'])\n",
    "        return weight_vals\n",
    "    def set_weights(self,weight_vals):\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "            self.sess.run(tf.assign(weight_tf_var,weight_vals[w_idx]))\n",
    "    def rollout(self,n_rollout=10,seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed=seed)\n",
    "        o_random = np.random.rand(n_rollout,self.odim)\n",
    "        mu_vals = self.sess.run(self.model['mu'],feed_dict={self.model['o_ph']:o_random})\n",
    "        return mu_vals\n",
    "    \n",
    "@ray.remote\n",
    "class RayRolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Rollout Worker with RAY\n",
    "    \"\"\"\n",
    "    def __init__(self,worker_id=0,odim=10,adim=2):\n",
    "        self.worker_id = worker_id\n",
    "        self.odim = odim\n",
    "        self.adim = adim\n",
    "        self.model,self.sess = create_sac_model(odim=self.odim,adim=self.adim)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def get_weights(self):\n",
    "        weight_vals = self.sess.run(self.model['main_vars'])\n",
    "        return weight_vals\n",
    "    def set_weights(self,weight_vals):\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "            self.sess.run(tf.assign(weight_tf_var,weight_vals[w_idx]))\n",
    "    def rollout(self,n_rollout=10,seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed=seed)\n",
    "        o_random = np.random.rand(n_rollout,self.odim)\n",
    "        mu_vals = self.sess.run(self.model['mu'],feed_dict={self.model['o_ph']:o_random})\n",
    "        return mu_vals\n",
    "    \n",
    "print (\"Rollout worker classes (with and without RAY) ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a single <font color='red'> *CentralWorker* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single centralized worker initialized.\n"
     ]
    }
   ],
   "source": [
    "odim,adim = 10,2\n",
    "tf.reset_default_graph()\n",
    "R = RolloutWorkerClass(odim=odim,adim=adim)\n",
    "print (\"Single centralized worker initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multiple <font color='blue'> *RayWorkers* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] workers initialized.\n"
     ]
    }
   ],
   "source": [
    "n_workers = 5\n",
    "workers = [RayRolloutWorkerClass.remote(\n",
    "    worker_id=i,odim=odim,adim=adim) for i in range(n_workers)]\n",
    "print (\"[%d] workers initialized.\"%(n_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout of <font color='red'> *CentralWorker* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout result of the central worker is:\n",
      "[[0.15 0.07]\n",
      " [0.02 0.08]]\n"
     ]
    }
   ],
   "source": [
    "rollout_val = R.rollout(n_rollout=2,seed=0)\n",
    "print (\"Rollout result of the central worker is:\\n%s\"%(rollout_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout of <font color='blue'> *RayWorkers* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18456)\u001b[0m WARNING:tensorflow:From <ipython-input-4-f54507ead842>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18456)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18456)\u001b[0m Use keras.layers.dense instead.\n",
      "\u001b[2m\u001b[36m(pid=18459)\u001b[0m WARNING:tensorflow:From <ipython-input-4-f54507ead842>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18459)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18459)\u001b[0m Use keras.layers.dense instead.\n",
      "\u001b[2m\u001b[36m(pid=18457)\u001b[0m WARNING:tensorflow:From <ipython-input-4-f54507ead842>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18457)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18457)\u001b[0m Use keras.layers.dense instead.\n",
      "\u001b[2m\u001b[36m(pid=18460)\u001b[0m WARNING:tensorflow:From <ipython-input-4-f54507ead842>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18460)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18460)\u001b[0m Use keras.layers.dense instead.\n",
      "\u001b[2m\u001b[36m(pid=18458)\u001b[0m WARNING:tensorflow:From <ipython-input-4-f54507ead842>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18458)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18458)\u001b[0m Use keras.layers.dense instead.\n",
      "\u001b[2m\u001b[36m(pid=18456)\u001b[0m WARNING:tensorflow:From /home/sj/.adt/venv-adt/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18456)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18456)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[2m\u001b[36m(pid=18459)\u001b[0m WARNING:tensorflow:From /home/sj/.adt/venv-adt/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18459)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18459)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[2m\u001b[36m(pid=18457)\u001b[0m WARNING:tensorflow:From /home/sj/.adt/venv-adt/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18457)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18457)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[2m\u001b[36m(pid=18458)\u001b[0m WARNING:tensorflow:From /home/sj/.adt/venv-adt/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18458)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18458)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[2m\u001b[36m(pid=18460)\u001b[0m WARNING:tensorflow:From /home/sj/.adt/venv-adt/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=18460)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=18460)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Rollout result of [0] worker is:\n",
      " [[-0.04 -0.14]\n",
      " [-0.09 -0.07]]\n",
      "Rollout result of [1] worker is:\n",
      " [[ 0.21 -0.34]\n",
      " [ 0.26 -0.3 ]]\n",
      "Rollout result of [2] worker is:\n",
      " [[-0.2  -0.02]\n",
      " [-0.14  0.18]]\n",
      "Rollout result of [3] worker is:\n",
      " [[-0.05 -0.14]\n",
      " [-0.14 -0.21]]\n",
      "Rollout result of [4] worker is:\n",
      " [[ 0.01  0.05]\n",
      " [-0.04  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "ops = [worker.rollout.remote(n_rollout=2,seed=0) for worker in workers] # non-block\n",
    "rollout_vals = ray.get(ops)\n",
    "for r_idx,rollout_val in enumerate(rollout_vals):\n",
    "    print (\"Rollout result of [%d] worker is:\\n %s\"%(r_idx,rollout_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the weights of <font color='red'> *CentralWorker* </font> &#10140; <font color='blue'> *RayWorkers* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = R.get_weights()\n",
    "set_weights_list = [worker.set_weights.remote(weights) for worker in workers] # non-block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rollout results of <font color='blue'> *RayWorkers* </font> should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout result of [0] worker is:\n",
      " [[0.15 0.07]\n",
      " [0.02 0.08]]\n",
      "Rollout result of [1] worker is:\n",
      " [[0.15 0.07]\n",
      " [0.02 0.08]]\n",
      "Rollout result of [2] worker is:\n",
      " [[0.15 0.07]\n",
      " [0.02 0.08]]\n",
      "Rollout result of [3] worker is:\n",
      " [[0.15 0.07]\n",
      " [0.02 0.08]]\n",
      "Rollout result of [4] worker is:\n",
      " [[0.15 0.07]\n",
      " [0.02 0.08]]\n"
     ]
    }
   ],
   "source": [
    "ops = [worker.rollout.remote(n_rollout=2,seed=0) for worker in workers] # non-block\n",
    "rollout_vals = ray.get(ops)\n",
    "for r_idx,rollout_val in enumerate(rollout_vals):\n",
    "    print (\"Rollout result of [%d] worker is:\\n %s\"%(r_idx,rollout_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update <font color='red'> *CentralWorker* </font> with Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rand = np.random.rand\n",
    "feed_dict = {\n",
    "    R.model['o_ph']:rand(batch_size,R.odim),\n",
    "    R.model['o2_ph']:rand(batch_size,R.odim),\n",
    "    R.model['a_ph']:rand(batch_size,R.adim),\n",
    "    R.model['r_ph']:rand(batch_size),\n",
    "    R.model['d_ph']:np.zeros(batch_size)\n",
    "}\n",
    "outs = R.sess.run(R.step_ops, feed_dict) # train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the weights of <font color='red'> *CentralWorker* </font> &#10140; <font color='blue'> *RayWorkers* </font>  and Rollout <font color='blue'> *RayWorkers* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout result of [0] worker is:\n",
      " [[0.19 0.27]\n",
      " [0.07 0.29]]\n",
      "Rollout result of [1] worker is:\n",
      " [[0.19 0.27]\n",
      " [0.07 0.29]]\n",
      "Rollout result of [2] worker is:\n",
      " [[0.19 0.27]\n",
      " [0.07 0.29]]\n",
      "Rollout result of [3] worker is:\n",
      " [[0.19 0.27]\n",
      " [0.07 0.29]]\n",
      "Rollout result of [4] worker is:\n",
      " [[0.19 0.27]\n",
      " [0.07 0.29]]\n"
     ]
    }
   ],
   "source": [
    "weights = R.get_weights()\n",
    "set_weights_list = [worker.set_weights.remote(weights) for worker in workers] # non-block\n",
    "ops = [worker.rollout.remote(n_rollout=2,seed=0) for worker in workers] # non-block\n",
    "rollout_vals = ray.get(ops)\n",
    "for r_idx,rollout_val in enumerate(rollout_vals):\n",
    "    print (\"Rollout result of [%d] worker is:\\n %s\"%(r_idx,rollout_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown RAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAY shutdown.\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "print (\"RAY shutdown.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
